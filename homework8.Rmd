---
title: "Homework 8 -- Due Monday November 9, 2015"
author: "Cheryl Calhoun"
date: "11/02/2015"
output: html_document
---

```{r, eval=FALSE, echo=FALSE}
## install.packages("twitteR")
## install.packages("base64enc")  ## This solved some of my problems, so you should install it too.
```

```{r, eval=TRUE, echo=TRUE, warning=FALSE, message=FALSE}
## Setting up the work environment and twitteR API
##setwd("C:/Users/07001412/OneDrive/Education/UF/2015/Fall/EDF6938/Week 10")
library("twitteR") ##, lib.loc="~/R/win-library/3.2")
library("base64enc") ##, lib.loc="~/R/win-library/3.2")
library("dplyr") ##, lib.loc="~/R/win-library/3.2")
##download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem") ##-- this was suggested if you are running a Windows machine.

## Loading twitter API and Access keys.
source ("twitter-access-keys.R")
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)

## Setting search patterns.
usertag <- "@[A-z_0-9]+"
hashtag <- "#[A-z0-9]+"

```

###Gathering data on Football related tweets at the University of Florida

Context: Every member of the class was assigned a school in the Southeastern Conference (SEC) as specified in the spreadsheet located at: [https://docs.google.com/spreadsheets/d/1IKRXc0hN1C9e5S845LmgY-rlLdCQ1xOQrI3thxKIgVA/edit?usp=sharing]

For this exercise, data will be captured from twitter each week, saved to a file, and reload from that file as needed. This will ensure both reproducibility and ease of use on Twitter's servers.

The original plan was to use geolocation to find our tweets.  To do this, we need to find the latitude and longitude of our school on Google Maps. (This is a manual process of looking up the coordinates.) The latitude and longitude of Ben Hill Griffin stadium at the University of Florida is: 29.649898, -82.348429. Now, we can use these coordinates to extract a sample of tweets from near that location.  For this exercise, we will use a 5 mile radius.  

Unfortunately, geolocation does not seem to work, so we will use the most common hasgtag associated with Florida Sports and Florida Football.  After some initial data exploration, the #GoGators hashtag is selected.

There are four remaining games this season. They are:

Game #  | Date   | Opponent      | Location
--------|--------|---------------|-------------
Game 9  | Nov 7  | Vanderbilt    | Gainesville
Game 10 | Nov 14 | S. Carolina   | Columbia
Game 11 | Nov 21 | Fl. Atlantic  | Gainesville
Game 12 | Nov 28 | Florida State | Gainesville

```{r, eval=TRUE, echo=TRUE, warning=FALSE, message=FALSE}

## Collect weekly tweets beginning Thursday before game and ending on Sunday after the game. Store tweets in a .csv file.  This code will be executed on a weekly basis until we have gathered data for the remaining 4 games of the season. 

##The original geolocation code.
## Florida <- searchTwitter('', geocode='29.649898,-82.348429,5mi', since="2015-11-05", until="2015-11-09", n=10000)

##The updated #GoGators hashtag code.
##Florida <- searchTwitter("#UFvsVU", geocode='29.649898,-82.348429,5mi', since="2015-11-05", until="2015-11-09", n=10000, retryOnRateLimit=120)
##Florida.df <- rbind_all (lapply (Florida, function(rr) rr$toDataFrame()))
##write.csv(Florida.df, file = "Vanderbilt2.csv")

## Collect data for game 10
##Florida <- searchTwitter("#GoGators", since="2015-11-12", until="2015-11-16", n=10000, retryOnRateLimit=120)
##Florida2 <- searchTwitter("#UFvsSC", geocode='29.649898,-82.348429,5mi', since="2015-11-12", until="2015-11-16", n=10000, retryOnRateLimit=120)
##Florida.df <- rbind_all (lapply (Florida, function(rr) rr$toDataFrame()))
##write.csv(Florida.df, file = "Carolina.csv")

## Collect data for game 11
##Florida <- searchTwitter("#GoGators", since="2015-11-19", until="2015-11-23", n=10000)
##Florida.df <- rbind_all (lapply (Florida, function(rr) rr$toDataFrame()))
##write.csv(Florida.df, file = "FLAtl.csv")

## Collect data for game 12
##Florida <- searchTwitter("#GoGators", since="2015-11-26", until="2015-11-30", n=10000)
##Florida.df <- rbind_all (lapply (Florida, function(rr) rr$toDataFrame()))
##write.csv(Florida.df, file = "FloridaSt.csv")

#Read previously stored data from data file.
Game9 <- read.csv("Vanderbilt.csv")
## Game10 <- read.csv("Carolina.csv")
## Game11 <- read.csv("FLAtl.csv")
## Game12 <- read.csv("FloridaSt.csv")

```

####Game 9: Vanterbilt

#####Evaluating HashTags

Determining the number of hashtags used in each tweet and overall in the sample.

```{r}

## Find hashtags for Game 9. Add a column for hashtags and a column for number of hashtags.
Game9 <- mutate (Game9, hashtags=regmatches(Game9$text, gregexpr(hashtag, Game9$text)))
Game9 <- mutate (Game9, HQty=as.integer(lapply(Game9$hashtags, function(x) length(x))))

```

The number of tweets at each hashtag level
```{r}
## Create a Hashtags per Tweet table.
HashtagsperTweet = table(Game9$HQty)
HashtagsperTweetTable = as.data.frame(HashtagsperTweet)
names(HashtagsperTweetTable)[1] = 'Number of Hashtags'
names(HashtagsperTweetTable)[2] = 'Number of Tweets'
HashtagsperTweetTable
```

The total number of hashtags in the data set.
```{r}
## Determine total number of hashtags.
all.hashtags <- unlist(regmatches(Game9$text, gregexpr (hashtag, Game9$text)))
## all.hashtags
length(all.hashtags)
```

The total number of unique hashtags in the data set.
```{r}
## Determine total number of unique hashtags.
unique.hashtags <- unique(all.hashtags <- unlist(regmatches(Game9$text, gregexpr (hashtag, Game9$text))))
length(unique.hashtags)

```

Finding the most frequently used hashtags.
```{r}
## Count the hashtag usage.
hashtags.df <- data.frame(cbind(all.hashtags))
hashcount <- count(hashtags.df, all.hashtags)
hashcount <- hashcount[order(-hashcount$n),] 
hashcount
```

#####Evaluating UserTags

Determining the number of users tagged in each tweet. 

```{r}

## Find users for game 9.Add a column for usertags and a column for number of user tags in the tweet.
##Game9 <- mutate (Game9, usertags=regmatches(Game9$text, gregexpr(users, Game9$text)))
##Game9 <- mutate (Game9, UQty=as.integer(lapply(Game9$users, function(x) length(x))))

Game9 <- mutate (Game9, usertags=regmatches(Game9$text, gregexpr(usertag, Game9$text)))
Game9 <- mutate (Game9, UQty=as.integer(lapply(Game9$usertags, function(x) length(x))))
```

The number of users tagged per tweet.
```{r}
## Create a Hashtags per Tweet table.
UserTagsperTweet = table(Game9$UQty)
UserTagsperTweetTable = as.data.frame(UserTagsperTweet)
names(UserTagsperTweetTable)[1] = 'Number of Users'
names(UserTagsperTweetTable)[2] = 'Number of Tweets'
UserTagsperTweetTable
```
The total number of usertags in the data set.
```{r}
## Determine total number of hashtags.
all.usertags <- unlist(regmatches(Game9$text, gregexpr (usertag, Game9$text)))
## all.hashtags
length(all.usertags)
```

The total number of unique usertags in the data set.
```{r}
## Determine total number of unique hashtags.
unique.usertags <- unique(all.usertags <- unlist(regmatches(Game9$text, gregexpr (usertag, Game9$text))))
length(unique.usertags)

```

Finding the most commonly used usertags.
```{r}
## Count the hashtag usage.
usertags.df <- data.frame(cbind(all.usertags))
usercount <- count(usertags.df, all.usertags)
usercount <- usercount[order(-usercount$n),] 
usercount
```

###Gathering Data for Games 10-12 - Coming soon...
Collect a set of 10000 tweets for each of the last five ***Thursday-Saturday*** blocks on which a football game was played by the University of Florda. Repeat the hashtag collection and user tagging exercises for each of these samples. Do the same users appear to produce the same volume each week? Do the same secondary hashtags appear?

```{r}
## Games 10-12 coming soon...

```

The following 25 users tweeted most frequently during the game 9 period.  The usertags were selected after eliminating users that were clearly accounts for the team proper or their PR department. That is, we're trying to find a fan community for your team that tweets about their team's games on a regular basis. This community will form the basis for the project looking ahead.

```{r eval=TRUE, echo=TRUE, warning=FALSE, message=FALSE}
## Count the hashtag usage.
frequenttweeters <- summarise(group_by(Game9, screenName), count=n())
frequenttweeters <- frequenttweeters[order(-frequenttweeters$count),]
head(frequenttweeters, 25)
```

The top 25 tweeters are:

SECstagram, 
HotCorner_10, 
gogators1974, 
MrMarques2727, 
Trippo7, 
Tebow815, 
CliffWilkin, 
_Whoa_itsPayge_, 
jhern2498, 
TampaBaySRH, 
2103_amber, 
bmanning96, 
major1029, 
ClaireabellGatr, 
CVan_Huss, 
hunterlynch29, 
krizielyvonne, 
REGarrison, 
ktharris, 
rebeccavelaz17, 
TOTODUVALDIVA, 
BrookinsOneil, 
ChristophersZen, 
Emmy_ArmadaFC, 
Gatorfan187